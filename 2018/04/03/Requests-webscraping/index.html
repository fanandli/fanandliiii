<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Requests库详解 | turlee&#39;s blog</title>

  
  <meta name="author" content="turlee">
  

  
  <meta name="description" content="真正危险的不是计算机开始像人那样去思考，而是人类开始像计算机一样思考。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;      &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;——西德尼·哈里斯（Sydney Harris）

python爬虫之旅之第二站~~
Requests库是经常用的库，比urllib更加方便。首先先领略一下使用Requests的方便之处：1234567import requestsresponse=requests.get(&#39;http://aisleep.xyz&#39;)print(type(response))print(response.status_code)print(type(response.text))print(response.text)print(response.cookies)
这里的第6行和在urllib中使用read的作用是一样的，在urllib中还要使用.decode使得其变成字符串类型。在Requests中就很方便了，直接使用text就可以了。在最后一行中的cookies获取中也比在urllib中方便很多。">
  

  
  
  <meta name="keywords" content="python,web-scraping">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="Requests库详解">

  <meta property="og:site_name" content="turlee&#39;s blog">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="turlee&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">turlee&#39;s blog</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/about">About</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>Requests库详解</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/04/03/Requests-webscraping/" rel="bookmark">
        <time class="entry-date published" datetime="2018-04-03T01:52:53.000Z">
          2018-04-03
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <blockquote>
<p>真正危险的不是计算机开始像人那样去思考，而是人类开始像计算机一样思考。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;——西德尼·哈里斯（Sydney Harris）</p>
</blockquote>
<p><code>python</code><strong><em>爬虫之旅之第二站~~</em></strong></p>
<p><code>Requests</code>库是经常用的库，比<code>urllib</code>更加方便。<br>首先先领略一下使用<code>Requests</code>的方便之处：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">'http://aisleep.xyz'</span>)</span><br><span class="line">print(type(response))</span><br><span class="line">print(response.status_code)</span><br><span class="line">print(type(response.text))</span><br><span class="line">print(response.text)</span><br><span class="line">print(response.cookies)</span><br></pre></td></tr></table></figure></p>
<p>这里的第6行和在<code>urllib</code>中使用<code>read</code>的作用是一样的，在<code>urllib</code>中还要使用<code>.decode</code>使得其变成字符串类型。在<code>Requests</code>中就很方便了，直接使用<code>text</code>就可以了。在最后一行中的<code>cookies</code>获取中也比在<code>urllib</code>中方便很多。</p>
<a id="more"></a>
<p>再看<code>requests</code>中还提供了很多比较方便的各种请求方式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">requests.post(<span class="string">"http://httpbin.org/post"</span>)</span><br><span class="line">requests.put(<span class="string">"http://httpbin.org/put"</span>)</span><br><span class="line">requests.delete(<span class="string">"http://httpbin.org/delete"</span>)</span><br><span class="line">requests.head(<span class="string">"http://httpbin.org/get"</span>)</span><br><span class="line">requests.options(<span class="string">"http://htpbin.org/get"</span>)</span><br></pre></td></tr></table></figure></p>
<p>可见想要进行一个<code>post</code>请求，直接<code>requests.post</code>就好。</p>
<hr>
<p>好，<code>Requsets</code>的方便之处你现在也稍微感受到一点了，现在在仔细的看一下他的使用。</p>
<ul>
<li><code>get</code>请求</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">'http://aisleep.xyz'</span>)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure>
<p>这里就是一个最简单的一个<code>get</code>请求。那如果我们还要传一些自己的参数怎么设置呢：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">"http://httpbin.org/get?name=lifan&amp;age=23"</span>)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure></p>
<p>也可以这样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">data=&#123;</span><br><span class="line">	<span class="string">'name'</span>:<span class="string">'lifan'</span>,</span><br><span class="line">	<span class="string">'age'</span>:<span class="number">23</span></span><br><span class="line">&#125;</span><br><span class="line">response=requests.get(<span class="string">"http://httpbin.org/get"</span>,params=data)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure></p>
<p>第一种方法比较繁琐一点，需要加一个<code>?</code>再在多个参数之间再加上<code>&amp;</code>就可以。第二种方法就是自己先构造一个字典，然后传给<code>params</code>就可以方便的构造一个<code>get</code>请求的<code>url</code>，不需要再手动输入了。</p>
<ul>
<li>解析<code>json</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">"http://httpbin.org/get"</span>)</span><br><span class="line">print(type(response.text))</span><br><span class="line">print(response.json())</span><br><span class="line">print(type(response.json()))</span><br></pre></td></tr></table></figure>
<p>这是直接提供的了个解析<code>json</code>格式的方式，其实第4行就相当于进行一个这样的调用：<code>print(json.load(response.text))</code>(在前面再加一句<code>import json</code>)</p>
<ul>
<li>获取二进制数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">"https://github.com/favicon.ico"</span>)</span><br><span class="line">print(type(response.text),type(response.content))</span><br><span class="line">print(response.text)</span><br><span class="line">print(response.content)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'favicon.ico'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">	f.write(response.content)</span><br><span class="line">	f.close()</span><br></pre></td></tr></table></figure>
<p>这里使用<code>content</code>获取二进制数据，比如图片，视频等，第6行开始到结束做的是保存这个二进制文件的工作：打开一个文件，<code>wb</code>是说明对这个文件进行操作的方式为“以二进制格式打开一个文件只用于写入”，<code>as f</code>是帮这个文件起了一个别名，<code>f.write</code>是写入到打开的文件中，最后要关闭文件。</p>
<ul>
<li><code>header</code>添加</li>
</ul>
<p>添加<code>headers</code>主要是模拟成你是浏览器要求的访问，防止被浏览网站所禁止。这里添加一个浏览器信息就好<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers=&#123;</span><br><span class="line">	<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Macintosh; intel Mac OS X 10_11_4) AppleWebKit/537.36(KHTML,like Gecko)Chrome/52.0.2743.116 Safari/537.36'</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">response=requests.get(<span class="string">'http://www.zhihu.com'</span>,headers=headers)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>基本的<code>post</code>请求</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">data=&#123;<span class="string">'name'</span>:<span class="string">'lifan'</span>,<span class="string">'age'</span>:<span class="string">'23'</span>&#125;</span><br><span class="line">response=requests.post(<span class="string">"http://httpbin.org/post"</span>,data=data)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure>
<p>这里就明显看出比<code>urllib</code>中的操作方便很多。</p>
<ul>
<li><code>response</code>属性</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(type(response.status_code),response.status_code)</span><br><span class="line">print(type(response.headers),response.headers)</span><br><span class="line">print(type(response.cookies),response.cookies)</span><br><span class="line">print(type(response.url),response.url)</span><br><span class="line">print(type(response.history),response.history)</span><br></pre></td></tr></table></figure>
<p>运行结果为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &apos;int&apos;&gt; 200</span><br><span class="line">&lt;class &apos;requests.structures.CaseInsensitiveDict&apos;&gt; &#123;&apos;Server&apos;: &apos;bfe/1.0.8.18&apos;, &apos;Date&apos;: &apos;Tue, 03 Apr 2018 07:59:03 GMT&apos;, &apos;Content-Type&apos;: &apos;text/html&apos;, &apos;Last-Modified&apos;: &apos;Mon, 23 Jan 2017 13:27:36 GMT&apos;, &apos;Transfer-Encoding&apos;: &apos;chunked&apos;, &apos;Connection&apos;: &apos;Keep-Alive&apos;, &apos;Cache-Control&apos;: &apos;private, no-cache, no-store, proxy-revalidate, no-transform&apos;, &apos;Pragma&apos;: &apos;no-cache&apos;, &apos;Set-Cookie&apos;: &apos;BDORZ=27315; max-age=86400; domain=.baidu.com; path=/&apos;, &apos;Content-Encoding&apos;: &apos;gzip&apos;&#125;</span><br><span class="line">&lt;class &apos;requests.cookies.RequestsCookieJar&apos;&gt; &lt;RequestsCookieJar[&lt;Cookie BDORZ=27315 for .baidu.com/&gt;]&gt;</span><br><span class="line">&lt;class &apos;str&apos;&gt; http://www.baidu.com/</span><br><span class="line">&lt;class &apos;list&apos;&gt; []</span><br></pre></td></tr></table></figure></p>
<ul>
<li>状态码判断</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">exit() <span class="keyword">if</span> <span class="keyword">not</span> response.status_code==requests.codes.ok <span class="keyword">else</span> print(<span class="string">'request successfully'</span>)</span><br></pre></td></tr></table></figure>
<p>这个状态码的判断的意思是，在<code>requests.codes</code>里面他将很多的状态码对应了一些方便记忆的单词，比如，将<code>200</code>对应了<code>ok</code>这个词，<code>404</code>对应了<code>not_found</code>这个词，这样我们只要查表不需要记住这些状态码就行了，第3行的代码的意思是：如果<code>response</code>的状态码不等于<code>ok</code>就退出，如果等于，就打印<code>request successfully</code>。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/python/">python</a><a href="/tags/web-scraping/">web-scraping</a>
    </span>
    

    </div>

    
  </div>
</article>


    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy; 2019 turlee
    
  </p>
</footer>
    
  </div>
</div>
</body>
</html>